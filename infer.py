# coding:utf-8
"""
RF-DETRæ¨ç†æµ‹è¯•è„šæœ¬
éªŒè¯è®­ç»ƒå¥½çš„æ¨¡å‹èƒ½å¤Ÿæ­£å¸¸è¿›è¡Œæ£€æµ‹ä»»åŠ¡
"""

import torch
import cv2
import numpy as np
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
from rfdetr import RFDETRNano
import supervision as sv
import time


def load_trained_model(checkpoint_path='runs/train_rf-detr-s/checkpoint_best_regular.pth'):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    Args:
        checkpoint_path: è®­ç»ƒcheckpointè·¯å¾„
    
    Returns:
        loaded model
    """
    print(f"æ­£åœ¨åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹: {checkpoint_path}")
    
    if not Path(checkpoint_path).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        
        # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶ - ä¼˜å…ˆæ£€æŸ¥æ–°çš„runsç›®å½•ç»“æ„
        search_dirs = [
            Path("runs/train_rf-detr-n"),  # æ–°çš„ç›®å½•ç»“æ„
        ]
        
        checkpoint_path = None
        for search_dir in search_dirs:
            if search_dir.exists():
                available_models = list(search_dir.glob("checkpoint_best_*.pth"))
                if available_models:
                    print(f"âœ“ åœ¨{search_dir}ä¸­å‘ç°ä»¥ä¸‹å¯ç”¨æ¨¡å‹:")
                    for model in available_models:
                        print(f"  - {model.name}")
                    checkpoint_path = available_models[0]
                    print(f"ä½¿ç”¨: {checkpoint_path}")
                    break
        
        if checkpoint_path is None:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
            print("è¯·ç¡®ä¿å·²å®Œæˆè®­ç»ƒï¼Œæˆ–æ£€æŸ¥ä»¥ä¸‹ç›®å½•:")
            for search_dir in search_dirs:
                print(f"  - {search_dir}")
            return None
    
    try:
        # é¦–å…ˆåŠ è½½checkpointè·å–æ­£ç¡®çš„é…ç½®
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        
        # ä»checkpointä¸­è·å–æ­£ç¡®çš„ç±»åˆ«æ•°é‡
        # RF-DETRä¼šè‡ªåŠ¨å°†num_classes+1ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä»æƒé‡å½¢çŠ¶åæ¨
        if 'model' in checkpoint and 'class_embed.weight' in checkpoint['model']:
            actual_num_classes = checkpoint['model']['class_embed.weight'].shape[0]
            # ç”±äºRF-DETRå†…éƒ¨ä¼š+1ï¼Œæ‰€ä»¥æˆ‘ä»¬è®¾ç½®ä¸ºactual_num_classes-1
            num_classes = actual_num_classes - 1 if actual_num_classes > 1 else actual_num_classes
            print(f"âœ“ ä»æƒé‡å½¢çŠ¶æ¨æ–­: å®é™…æƒé‡{actual_num_classes}ç±»ï¼Œè®¾ç½®num_classes={num_classes}")
        else:
            num_classes = 3  # é»˜è®¤3ï¼Œè®©RF-DETRè‡ªåŠ¨+1å˜æˆ4
            print(f"âœ“ ä½¿ç”¨é»˜è®¤ç±»åˆ«æ•°: {num_classes}")
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹ - ä½¿ç”¨è®¡ç®—åçš„ç±»åˆ«æ•°é‡
        model = RFDETRNano(num_classes=num_classes, pretrain_weights=None)
        
        # åŠ è½½æ¨¡å‹æƒé‡ - æ­£ç¡®çš„ç»“æ„æ˜¯ model.model.model
        if 'model' in checkpoint:
            # è¿‡æ»¤æ‰ä¸åŒ¹é…çš„class_embedæƒé‡
            state_dict = checkpoint['model']
            model_state_dict = model.model.model.state_dict()
            
            # æ£€æŸ¥å¹¶è¿‡æ»¤ä¸åŒ¹é…çš„æƒé‡
            filtered_state_dict = {}
            for k, v in state_dict.items():
                if k in model_state_dict:
                    if v.shape == model_state_dict[k].shape:
                        filtered_state_dict[k] = v
                    else:
                        print(f"âš  è·³è¿‡å½¢çŠ¶ä¸åŒ¹é…çš„æƒé‡: {k} {v.shape} vs {model_state_dict[k].shape}")
                else:
                    print(f"âš  è·³è¿‡ä¸å­˜åœ¨çš„æƒé‡: {k}")
            
            model.model.model.load_state_dict(filtered_state_dict, strict=False)
            print("âœ“ æˆåŠŸåŠ è½½å…¼å®¹çš„æ¨¡å‹æƒé‡")
        else:
            model.model.model.load_state_dict(checkpoint, strict=False)
            print("âœ“ æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡ (ç›´æ¥æ ¼å¼)")
        
        # è·å–è®­ç»ƒé…ç½®ä¿¡æ¯
        if 'args' in checkpoint:
            args = checkpoint['args']
            if hasattr(args, 'class_names'):
                print(f"âœ“ ç±»åˆ«åç§°: {args.class_names}")
                # ä¿å­˜ç±»åˆ«åç§°ä¾›åç»­ä½¿ç”¨
                model._inference_class_names = args.class_names
            else:
                # æ ¹æ®ç±»åˆ«æ•°é‡ç”Ÿæˆé€šç”¨ç±»åˆ«åç§°
                model._inference_class_names = [f'class_{i}' for i in range(num_classes)]
                print(f"âœ“ ä½¿ç”¨é€šç”¨ç±»åˆ«åç§°: {model._inference_class_names}")
        else:
            # æ ¹æ®ç±»åˆ«æ•°é‡ç”Ÿæˆé€šç”¨ç±»åˆ«åç§°
            model._inference_class_names = [f'class_{i}' for i in range(num_classes)]
            print(f"âœ“ ä½¿ç”¨é€šç”¨ç±»åˆ«åç§°: {model._inference_class_names}")
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.model.model.eval()
        
        # æ£€æŸ¥è®¾å¤‡
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.model.model = model.model.model.to(device)
        print(f"âœ“ æ¨¡å‹å·²åŠ è½½åˆ°: {device}")
        
        return model
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return None


def detect_image(model, image_path, confidence_threshold=0.3):
    """
    å¯¹å›¾åƒè¿›è¡Œæ£€æµ‹
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        image_path: å›¾åƒè·¯å¾„
        confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
    
    Returns:
        detections: æ£€æµ‹ç»“æœ
        image: åŸå§‹å›¾åƒ
    """
    print(f"\næ­£åœ¨æ£€æµ‹å›¾åƒ: {image_path}")
    
    if not Path(image_path).exists():
        print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return None, None
    
    try:
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path).convert('RGB')
        print(f"âœ“ å›¾åƒå°ºå¯¸: {image.size}")
        
        # å¼€å§‹æ¨ç†
        print(f"æ­£åœ¨è¿›è¡Œæ£€æµ‹... (ç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold})")
        start_time = time.time()
        
        # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        detections = model.predict(image_path, threshold=confidence_threshold)
        
        inference_time = time.time() - start_time
        print(f"âœ“ æ¨ç†å®Œæˆï¼Œè€—æ—¶: {inference_time:.3f}ç§’")
        
        # æ£€æŸ¥æ£€æµ‹ç»“æœ
        if len(detections.xyxy) > 0:
            print(f"âœ“ æ£€æµ‹åˆ° {len(detections.xyxy)} ä¸ªç›®æ ‡")
            
            # æ˜¾ç¤ºæ£€æµ‹è¯¦æƒ…
            for i, (bbox, confidence, class_id) in enumerate(zip(detections.xyxy, detections.confidence, detections.class_id)):
                class_name = model.class_names[class_id] if hasattr(model, 'class_names') and class_id < len(model.class_names) else f"class_{class_id}"
                print(f"  ç›®æ ‡ {i+1}: {class_name} (ç½®ä¿¡åº¦: {confidence:.3f})")
                print(f"          è¾¹ç•Œæ¡†: [{bbox[0]:.1f}, {bbox[1]:.1f}, {bbox[2]:.1f}, {bbox[3]:.1f}]")
        else:
            print("âš  æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
        
        return detections, image
        
    except Exception as e:
        print(f"âŒ æ£€æµ‹å¤±è´¥: {e}")
        return None, None


def visualize_results(image, detections, model, output_path='detection_result.jpg'):
    """
    å¯è§†åŒ–æ£€æµ‹ç»“æœ
    
    Args:
        image: åŸå§‹å›¾åƒ
        detections: æ£€æµ‹ç»“æœ
        output_path: ä¿å­˜è·¯å¾„
    """
    print(f"\næ­£åœ¨ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
    
    try:
        # åˆ›å»ºå›¾åƒå‰¯æœ¬ç”¨äºç»˜åˆ¶
        vis_image = image.copy()
        draw = ImageDraw.Draw(vis_image)
        
        # å°è¯•åŠ è½½å­—ä½“
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except:
            font = ImageFont.load_default()
        
        # é¢œè‰²åˆ—è¡¨
        colors = [
            (255, 0, 0),    # çº¢è‰²
            (0, 255, 0),    # ç»¿è‰²
            (0, 0, 255),    # è“è‰²
            (255, 255, 0),  # é»„è‰²
        ]
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for i, (bbox, confidence, class_id) in enumerate(zip(detections.xyxy, detections.confidence, detections.class_id)):
            x1, y1, x2, y2 = bbox
            color = colors[class_id % len(colors)]
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
            
            # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
            if hasattr(model, '_inference_class_names') and model._inference_class_names:
                class_names_list = model._inference_class_names
            else:
                # åŠ¨æ€ç”Ÿæˆç±»åˆ«åç§°
                class_names_list = [f'class_{i}' for i in range(len(set(detections.class_id)))]
            
            class_name = class_names_list[class_id] if class_id < len(class_names_list) else f"class_{class_id}"
            label = f"{class_name}: {confidence:.3f}"
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            bbox_text = draw.textbbox((x1, y1-25), label, font=font)
            draw.rectangle(bbox_text, fill=color)
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
            draw.text((x1, y1-25), label, fill=(255, 255, 255), font=font)
        
        # ä¿å­˜ç»“æœ
        vis_image.save(output_path)
        print(f"âœ“ å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")
        
        # æ˜¾ç¤ºç»“æœä¿¡æ¯
        print(f"âœ“ æ£€æµ‹æ‘˜è¦:")
        print(f"  - æ€»ç›®æ ‡æ•°: {len(detections.xyxy)}")
        print(f"  - å¹³å‡ç½®ä¿¡åº¦: {detections.confidence.mean():.3f}")
        print(f"  - æœ€é«˜ç½®ä¿¡åº¦: {detections.confidence.max():.3f}")
        
        return vis_image
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        return None


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("RF-DETRæ¨¡å‹æ¨ç†æµ‹è¯•")
    print("éªŒè¯è®­ç»ƒå¥½çš„æ¨¡å‹æ£€æµ‹èƒ½åŠ›")
    print("=" * 60)
    
    # 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    model = load_trained_model()
    if model is None:
        print("âŒ æ— æ³•åŠ è½½æ¨¡å‹ï¼Œè¯·æ£€æŸ¥è®­ç»ƒæ˜¯å¦å®Œæˆ")
        return
    
    # 2. æ£€æŸ¥æµ‹è¯•å›¾åƒ
    test_image_path = "test1.jpg"
    
    # å¦‚æœtest1.jpgä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ç¤ºä¾‹å›¾åƒ
    if not Path(test_image_path).exists():
        print(f"âš  æµ‹è¯•å›¾åƒ {test_image_path} ä¸å­˜åœ¨")
        
        # å°è¯•ä½¿ç”¨RF-DETRè‡ªå¸¦çš„æµ‹è¯•å›¾åƒ
        example_image = "rfdetr/assets/test.jpg"
        if Path(example_image).exists():
            test_image_path = example_image
            print(f"âœ“ ä½¿ç”¨ç¤ºä¾‹å›¾åƒ: {test_image_path}")
        else:
            print("âŒ è¯·å°†æµ‹è¯•å›¾åƒå‘½åä¸º test1.jpg å¹¶æ”¾åœ¨RF-DETRç›®å½•ä¸‹")
            return
    
    # 3. è¿›è¡Œæ£€æµ‹
    detections, original_image = detect_image(model, test_image_path, confidence_threshold=0.3)
    
    if detections is None:
        print("âŒ æ£€æµ‹å¤±è´¥")
        return
    
    # 4. å¯è§†åŒ–ç»“æœ
    if len(detections.xyxy) > 0:
        result_image = visualize_results(original_image, detections, model, 'detection_result.jpg')
        if result_image:
            print("\nğŸ‰ æ£€æµ‹æµ‹è¯•å®Œæˆï¼")
            print("æ‚¨å¯ä»¥æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶:")
            print("  - detection_result.jpg: æ£€æµ‹ç»“æœå¯è§†åŒ–")
    else:
        print("\nâš  æœªæ£€æµ‹åˆ°ç›®æ ‡ï¼Œå¯èƒ½åŸå› :")
        print("  1. ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®è¿‡é«˜")
        print("  2. å›¾åƒä¸­æ²¡æœ‰è®­ç»ƒè¿‡çš„ç±»åˆ«ç›®æ ‡")
        print("  3. æ¨¡å‹éœ€è¦æ›´å¤šè®­ç»ƒ")
        
        # å°è¯•é™ä½é˜ˆå€¼é‡æ–°æ£€æµ‹
        print("\nå°è¯•é™ä½ç½®ä¿¡åº¦é˜ˆå€¼åˆ°0.1...")
        detections_low, _ = detect_image(model, test_image_path, confidence_threshold=0.1)
        if detections_low and len(detections_low.xyxy) > 0:
            visualize_results(original_image, detections_low, model, 'detection_result_low_threshold.jpg')
            print("âœ“ ä½é˜ˆå€¼æ£€æµ‹ç»“æœå·²ä¿å­˜ä¸º detection_result_low_threshold.jpg")


if __name__ == '__main__':
    main()